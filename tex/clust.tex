\documentclass[11pt,letterpaper]{article}

\usepackage[margin=1in]{geometry}
\usepackage{hyperref}
\usepackage{booktabs}
\usepackage[capitalise]{cleveref}
\usepackage{color}
\usepackage[dvipsnames]{xcolor}

\usepackage[group-separator={\,}]{siunitx}
\usepackage[noend]{algorithm2e}
\DontPrintSemicolon

\usepackage[sort,numbers]{natbib}
\renewcommand{\bibnumfmt}[1]{#1.}
%\bibliographystyle{IEEEtranN}
\usepackage{pgfplots}

\title{FgClust, a fast and scalable algorithm for generating large high-quality clusters of biological sequences}
\author{XiaoFei Zhao, ShingHei Zhan}

\begin{document}

\maketitle

\begin{abstract}
We developed FgClust, a novel multi-threaded algorithm for clustering biological sequences.
FgClust uses clique-aware all-versus-all search instead of greedy incremental update, min-hash values instead of short words, and the length of non-centroid sequence minus infix Levenshtein distance instead of sequence identity.
We evaluated FgClust, Linclust, MMSeqs2, CD-HIT, and kClust by using the PDB structures accessed on Jan 1\textsuperscript{st} 2017, five versions of UniRef100 released from July 2004 to Jan 2017, and Pfam-A-seed 31.0.
We evaluated FgClust, VSEARCH, and CD-HIT-EST by using Rfam 12.3.
Our evaluations show that FgClust always achieves the fastest runtime except Linclust and the best sensitivity-specificity trade-off without any exception.
Linclust is approximately two times faster but generates up to more than 130\% more clusters than FgClust.
The observed runtime of FgClust increases linearly with input size.
In one day, FgClust can cluster hundreds of millions of proteins, such as the ones in each expected release of UniProt in the next few years, into tens of millions of high-quality clusters.
FgClust is publicly available at \url{https://bitbucket.org/fusiongenomicscorp/pubclu}.
\end{abstract}

\section{Introduction}

Sequence clustering is a fundamental problem in Biology.
Sequences in the same cluster are supposed to be characterized by similar properties, such as three-dimensional structures, biological functions, and evolutionary origins.
Thus, we can predict the unknown properties of a sequence that is clustered together with another sequence with known properties.
A cluster containing multiple sequences can be represented by one representative sequence. 
Thus, clustering can lower the redundancy in a sequence database.

A more sensitive clustering algorithm is more likely to partition sequences with similar properties into the same cluster.
A more specific clustering algorithm is more likely to partition sequences with different properties into different clusters.
A more sensitive clustering algorithm generates fewer clusters of higher average cluster size.
A more specific clustering algorithm generates clusters of better average quality.

We developed FgClust, a novel sequence-clustering algorithm.
FgClust is publicly available at \url{https://bitbucket.org/fusiongenomicscorp/pubclu}.
The runtime of FgClust scales linearly with input size.
Thus, FgClust can scale to hundreds of millions of input sequences.
Compared with Linclust, MMSeqs2, CD-HIT, kClust, CD-HIT-EST, and VSEARCH, FgClust always achieves better sensitivity without compromising specificity, better specificity without compromising sensitivity, and faster runtime, except that Linclust is only faster than FgClust by approximately two times regardless of input size. 
However, Linclust generates up to more than 130\% more clusters than FgClust.
Moreover, the sensitivity of Linclust drops as the input database grows in size.

Our algorithmic novelties include the use of clique-aware all-versus-all search instead of greedy incremental update, the use of min-hash values instead of short words, and the use of Levenshtein distance instead of sequence alignment.
Moreover, we improved existing techniques, such as greedy set cover \cite{steinegger2017mmseqs2} and pruning of sorted hit candidates \cite{edgar2010search}, and combined these improved techniques with our algorithmic novelties.

\section{Approach}

Algorithm \ref{alg:fgclust} describes FgClust in detail. In sum, FgClust uses clique-aware all-versus-all search by min-hash values and Levenshtein distance.

\begin{algorithm}
\SetKwInOut{Parameter}{Parameter}
	\KwIn{Randomly shuffled nucleotide or amino-acid sequences}
	\KwOut{Partition of input sequences into clusters with one representative per cluster}
	\Parameter{Percent edit-similarity threshold \textnormal{percsim}% which affects any variable with the symbol \(x\)
	}
	\caption{FgClust \label{alg:fgclust}}
	\SetKwFunction{proc}{can-cover}
	\SetKwProg{myproc}{Subroutine}{}{}
	\myproc{\proc\((s_1, s_2):\)}{
		Compute the number \(d\) of single-character edits to make \(s_2\) a substring of \(s_1\).\;
		\KwRet \(4/5 \le \text{length}(s_1)/\text{length}(s_2) \le 5/4\)
		and \((s_2-d) \ge \sqrt{25^2 + (s_2\times \textnormal{percsim}/100)^2}\).\; 
	}
	Apply Murphy10 alphabet reduction on input if input is protein sequences.\;
	\For{each sequence in input}{
		Index some equally spaced long words, in the form of hash values, in the sequence.\;
	}
	\For{each indexed long word, in parallel}{
		\If{the long word occurs more than 1000 times in the index}{
			Uniformly and independently sample 800 pairs of sequences sharing this long word.\;
			Pick 10 pairs with the highest number of min-hash values shared by the pair.\;
			Initialize the number of true hits to zero.\;
			\For{each pair \((s_1, s_2)\) in these 10 pairs}{
				\lIf{\proc\((s_1, s_2)\)}{
					Increment the number of true hits by one.%.\;
				}
			}
			\If{the number of true hits is less than 5}{
				Remove the long word, which is regarded as non-informative, from the index.\;
			}
		}
	}
	\For{each sequence in input, in parallel}{
		Let the sequence be represented by its 32 min-hash values.\;	
	}
	Divide input sequences into chunks of sequences.\;
	\For{each chunk}{
		\For{each sequence \(s_1\) in the chunk, in parallel \textnormal{(LOOP2)}}{
			\If{\(s_1\) is covered less than \((150-\textnormal{percsim})/20\) times}{
				Let \(S_2\) be the list of sequences sharing at least one long word with \(s_1\).\;
				Sort \(S_2\), in descending order, by the number of min-hash values shared with \(s_1\).\;
				%Remove \(S_2\)  that shares less than certain number of min-hash values with \(s_1\).\;
				Initialize \(n\) to \(110-\textnormal{percsim}\).\;
				\For{each sequence \(s_2\) in \(S_2\) such that \(s_1\) and \(s_2\) share enough min-hash values}{
					\If{\(s_2\) is covered less than \((150-\textnormal{percsim})/5\) times}{
						\uIf{\proc\((s_1, s_2)\)}{
							Will apply the following update after LOOP2: let \(s_1\) cover \(s_2\).\;
							Increase \(n\) by \((110-\textnormal{percsim})\) and max out \(n\) at \((120-\textnormal{percsim})\).\;
						}\uElse{
							Decrease \(n\) by one.\;
						}
					}
					\lIf{\(n\) is zero}{
						exit loop.%.\;
					}
				}
			}
		}
	}
	Perform greedy set-cover on input sequences to produce a set \(R\) of representatives.\;
	For each input sequence, find its best representative in \(R\);
	\newline
\end{algorithm}

\subsection{Clique-aware all-versus-all search}

\Citet{li2001clustering} introduced the notion of greedy incremental update.
Greedy incremental update iterates through each sequence, usually in descending order by sequence length, and each iterated sequence either forms a new cluster or is covered by an existing cluster.
Thus, any not-yet iterated sequence that can be covered by an already iterated sequence cannot be a centroid.
However, a not-yet-iterated sequence can be a better centroid than the already iterated sequence.
Thus, such premature determination of centroid can result in more clusters of worse quality.
Instead, we can perform all-versus-all sequence-similarity search to construct a directed graph, and then solve the dominating-set problem on the resulting graph with greedy set cover.
In such graph, a vertex represents a sequence, and an edge from a first vertex to a second vertex means that the first sequence can represent and cover the second sequence.
Unfortunately, we observed that such graph is usually characterized by larger cliques as the number of input sequences increases.
Thus, naive determination of pairwise similarity between different sequences in the same clique results in slow and super-linear runtime.
Indeed, each sequence in a large clique can be represented by a large number of other sequences and is thus overrepresented.
However, we observed that only very few sub-sampled sequences in a clique are usually sufficient to represent all sequences represented by any sequence in the clique.
Thus, to achieve fast and linear runtime, FgClust prunes away any search where the query or target is an overrepresented sequence.
More specifically, FgClust iterates through each input sequence which is used as query.
During each iteration, if the query is overrepresented, then FgClust skips this iteration.
Otherwise, during this iteration, FgClust searches a list of targets that the query is likely to represent.
For each search, if the target is very overrepresented, then FgClust skips this search.

In other words, similar to canopy clustering \citep{mccallum2000efficient}, clique-aware all-versus-all search makes a trade-off between greedy incremental update and all-versus-all search. Compared with greedy incremental update, clique-aware all-versus-all delays centroid determination by performing lookahead and thus improves both sensitivity and specificity.
Compared with all-versus-all search, clique-aware all-versus-all discards any search that is unlikely to reduce the number of clusters by avoiding all-versus-all search in any large clique and thus asymptotically reduces runtime.
After clique-aware all-versus-all search, FgClust uses our implementation of greedy set cover on the resulting graph to generate a set of representative centroid sequences.
Then, each input sequence is clustered with the centroid sequence that can best represent the input sequence.
Our implementation of greedy set cover runs in linear time, is fast in practice, uses only twice the amount of memory required to specify the input as the input size is asymptotically large, and is memory-efficient in practice.

\subsection{Improved sequence search}

\Citet{li2002tolerating} used short-word filter in CD-HIT.
Short-word filter estimates the similarity between two sequences by counting their common short words.
Short word is also known as short k-mer.
However, a typical biological sequence has hundreds of short words.
Instead, FgClust transforms the short words of each input sequence into hash values and selects only the 32 lowest hash values.
Then, FgClust uses the lowest hash values, or equivalently min-hash values, as short words.
This reduction in short words reduces runtime.
We implemented, in FgClust, a version of rolling hash that generates pseudo-random hash values.

Sequence identity is the number of matches divided by the length of the shorter sequence in an alignment.
Usually, the blosum62 matrix with an affine gap penalty is used to compute such alignment.
However, such computation of alignment is time-consuming.
Moreover, sequence identity ignores deletions in the longer sequence.
Thus, sequence identity can overestimate the biological relatedness between two sequences.
Sequence alignment maximizes alignment score instead of the number of matches.
Thus, the biological relatedness implied by the number of matches can be lower than the biological relatedness implied by alignment score.
Thus, sequence identity can underestimate the biological relatedness between two sequences.
Instead of using sequence identity, we used edit-similarity in FgClust.
The edit-similarity between a query and a target is defined as follows: 
	the length of the target minus the minimum number of single-character edits required such that the edited target is a substring of the query.
	%, divided by the length of the target.
Then, the edit-similarity \(s\) is normalized to \(\sqrt{ s^2-(\min(c,s))^2}/L\), where \(c\) is a constant and \(L\) is the length of the target sequence.
\(c\) has a default value of 25, which is the minimum length of protein domains \citep[page 8]{niazi2016biosimilars}.
Edit-similarity takes less time to compute than sequence identity \citep{vsovsic2017edlib}.
Moreover, edit-similarity is more correlated with biological relatedness than sequence identity, as shown in \cref{table:pdb,fig:pfam,fig:rfam}.
Thus, the use of edit-similarity instead of sequence identity improves sensitivity, specificity, and runtime.
We used the library implemented by \citet{vsovsic2017edlib} to compute edit-similarity.

In addition of developing the aforementioned novel sequence-search techniques, we developed some variants of traditional sequence-search techniques.
To achieve linear worst-case runtime, Linclust selects only one representative sequence, or equivalently centroid, per k-mer.
However, \cref{fig:uniref} shows that Linclust loses increasingly more sensitivity as the input database grows in size. 
In fact, \cref{fig:uniref} shows that Linclust generates approximately 130\% more clusters than FgClust on UniRef100-2017-01.
FgClust achieves linear expected runtime without any significant loss in sensitivity.
Given a query sequence, FgClust searches only each input sequence that shares at least one informative long word with the query sequence.
A long word is a k-mer and is represented by its hash value.
To achieve linear expected runtime without significantly sacrificing sensitivity, FgClust uses longer long words for larger input size and ignores long words that are both abundant and uninformative.
A long word is uninformative if and only if two uniformly, randomly, and independently sampled sequences that share this long word usually do not share sufficiently high edit-similarity.
Thus, two sequences sharing only uninformative and abundant long words will be ignored in sequence search.
Two or more amino acids with similar biochemical properties can be reduced into one amino acid.
%For example, the unreduced alphabet of 20 standard amino acids can be reduced into an alphabet of 10-19 amino acids.
FgClust uses the Murphy10 amino-acid alphabet reduction suggested by \citet{murphy2000simplified} to improve sensitivity.
FgClust computes long words, min-hash values, and edit-similarities all with the reduced alphabet.
FgClust sorts in descending order target candidates by the number of min-hash values shared between the query and each target candidate.
FgClust initializes and then keeps track of a number of remaining attempts.
Each true-positive target candidate increases the number of remaining attempts.
Each false-positive target candidate decreases the number of remaining attempts.
The number of remaining attempts is capped at a certain value.
Similar to the pruning strategy used by \citet{edgar2010search}, the search terminates when the number of remaining attempts becomes negative to improve runtime.
All UniRef databases \citet{suzek2007uniref} were constructed by CD-HIT and required a minimum length overlap of 80\% \citep{suzek2014uniref}.
Similarly, FgClust requires the length of a query sequence to be between \(80\%\) and \(125\%\) of the length of a target sequence for the query sequence to possibly represent the target sequence. 
Similar to MMSeqs2 \citep{steinegger2017mmseqs2}, FgClust uses OpenMP to perform sequence search on multiple queries in parallel \citep{dagum1998openmp}.

\section{Evaluation on biological databases}

We evaluated every state-of-the-arts clustering algorithm on every gold-standard biological database.
Only the memory-limited 32-bit version of UCLUST is free and UCLUST is not open source \citep{edgar2010search}.
Thus, we omitted UCLUST in our evaluation.
Before any evaluation, we shuffled, by using a random-number generator with the same seed, the sequences in each biological database.
Thus, our evaluation results were both deterministically and yet pseudo-randomly generated to be both reproducible and yet unaffected by the order of sequences in a database.
All evaluations are done on a ``CentOS release 6.6'' server that runs on ``Intel(R) Xeon(R) CPU E5-2660 0 @ 2.20GHz'' with 16 cores and 32 threads.

\subsection{Evaluation on protein databases}

We compared FgClust commit 93c3a6d9 with CD-HIT version 4.6 \citep{fu2012cd}, Linclust commit 91644c75 \citep{steinegger2017linclust}, MMSeqs2 commit 91644c75 \citep{steinegger2017mmseqs2}, and kClust version 1.0 \citep{hauser2013kclust}. 
%kClust always has the worst sensitivity-specificity trade-off and is too time-consuming to be practical (data not shown). 
%Thus, the results of evaluation on kClust are not shown.

\begin{table}[t]%[!htbp]
	\centering
	\caption{
		The sequences of monomeric proteins in PDB accessed in January 1st 2017 are given as input to each program \citep{berman2006protein}. 
		Each program is run with each intra-cluster similarity threshold to generate each set of clusters.
		For each set of clusters, the number of clusters characterized by intra-cluster template-modeling (TM) scores inclusively below each threshold is tabulated.
		The intra-cluster TM score of a cluster is the lowest TM score between the representative sequence in the cluster as template and each represented sequence in the cluster.
		A cluster with an intra-cluster TM-score of less than 0.5 contains at least one outlier in terms of three-dimensional structure and is thus of bad quality \cite{xu2010significant}.
		FgClust generates the least number of bad-quality clusters.
		The runtime of each program is too short to measure wall-clock time and scalability.
	}
	\begin{tabular}{l c c c c c c c c c c}
		\toprule
		Program & intra-cluster & \multicolumn{9}{c}{intra-cluster TM scores} \\
		& similarity & 
		  \(\le\) 0.2 & \(\le\) 0.3 & \(\le\) 0.4 & \(\le\) 0.5 
		& \(\le\) 0.6 & \(\le\) 0.7 & \(\le\) 0.8 & \(\le\) 0.9 & \(\le\) 1.0 \\
		\midrule
		
		FgClust & 50 & 4 & 60 & 143 & 283 & 565 & 1020 & 1639 & 2606 & 14784 \\
		FgClust & 70 & 3 & 29 & 83 & 181 & 380 & 714 & 1208 & 1991 & 17538 \\
		FgClust & 90 & 2 & 9 & 31 & 90 & 197 & 401 & 739 & 1420 & 19993 \\

		Linclust & 50 & 28 & 108 & 232 & 380 & 617 & 975 & 1490 & 2298 & 17381 \\
		Linclust & 70 & 28 & 110 & 225 & 360 & 577 & 907 & 1382 & 2123 & 18207 \\
		Linclust & 90 & 20 & 85 & 177 & 302 & 479 & 763 & 1175 & 1889 & 19552 \\
	
		MMSeqs2 & 50 & 32 & 132 & 263 & 424 & 701 & 1113 & 1654 & 2499 & 15160 \\
		MMSeqs2 & 70 & 32 & 127 & 251 & 391 & 629 & 995 & 1475 & 2236 & 17158 \\
		MMSeqs2 & 90 & 35 & 111 & 217 & 358 & 549 & 826 & 1252 & 1962 & 18783 \\
		
		CD-HIT & 50 & 44 & 139 & 281 & 438 & 695 & 1114 & 1634 & 2440 & 15658 \\
		CD-HIT & 70 & 41 & 129 & 247 & 380 & 592 & 923 & 1398 & 2121 & 17610 \\
		CD-HIT & 90 & 33 & 115 & 226 & 344 & 517 & 782 & 1171 & 1852 & 19124 \\
		
		kClust & 50 & 29 & 114 & 250 & 397 & 628 & 1017 & 1530 & 2351 & 16108 \\
		kClust & 70 & 29 & 113 & 228 & 366 & 560 & 881 & 1335 & 2063 & 17682 \\
		kClust & 90 & 28 & 97 & 194 & 307 & 471 & 725 & 1083 & 1732 & 19707 \\
		\bottomrule
	\end{tabular}
	\label{table:pdb}
\end{table}

We assessed the sensitivity and specificity of FgClust by using experimentally verified data.
We downloaded all monomeric proteins with experimentally determined structures deposited into PDB exclusively before January 2nd 2017 \citep{berman2006protein}.
The sequence of each protein is extracted.
If an extracted sequence has at least 11 non-ambiguous amino acids and at least 90\% amino acids of the extracted sequence are non-ambiguous, then the extracted sequence is kept.
From these kept sequences, every sequence-clustering algorithm generates a set of clusters.
Within each cluster, the template-modeling (TM) score between the representative sequence and each represented sequence is computed by TM-Align developed by \citet{zhang2005tm}.
The lowest such TM score within each cluster is extracted and referred to as intra-cluster TM score.
The number of such intra-cluster TM scores below each threshold is shown in \cref{table:pdb}.
The lower such extracted TM scores are, the less specific the clustering algorithm is.
\Cref{table:pdb} shows that FgClust generates the fewest number of clusters with low intra-cluster TM scores.
Usually, two proteins are in the same fold if and only if these two proteins share a TM-score of at least 0.5 \citep{xu2010significant}, where a protein fold is defined by the arrangement of the secondary structure elements relative to each other in space.
\Cref{table:pdb} shows that other algorithms produce about 50\% more clusters with intra-cluster TM scores of less than 0.5 than FgClust.
Thus, FgClust is significantly more specific than other algorithms in terms of experimentally observed protein structures.
Moreover, FgClust at 50\% intra-cluster similarity generates the fewest number of clusters with the highest average cluster size.
Thus, FgClust is more sensitive than other algorithms in terms of experimentally observed protein structures.

We assessed the sensitivity and runtime of FgClust.
We downloaded the five versions of UniRef100 \citep{suzek2007uniref} shown in \cref{fig:uniref}.
Unlike NR, all previous versions of UniRef100 are available for download.
Unlike UniProtKB, the number of protein sequences in UniRef100 as a function of version release date is monotonically increasing.
Thus, we used UniRef100 instead of NR and UniProtKB in this assessment.
From each version of UniRef, we extracted protein sequences.
From these extracted sequences, each sequence-clustering algorithm generates a set of clusters.
The number of clusters produced by each algorithm and the runtime of each algorithm are shown in \cref{fig:uniref}.
A more sensitive clustering algorithm generates less number of clusters with larger average cluster size.
\Cref{fig:uniref} shows that FgClust generates the least number of clusters with the largest average cluster size.
Thus, FgClust is the most sensitive.
Moreover, \cref{fig:uniref} shows that FgClust is always faster than MMSeqs2, CD-HIT, and kClust.
FgClust is slower but significantly more sensitive than Linclust.
In fact, Linclust generates approximately 60\% and 130\% more clusters than FgClust at 50\% intra-cluster similarity on UniRef100-2.0 and UniRef100-2017-01, respectively.
Thus, the sensitivity of Linclust significantly decreases as the size of the input database increases. 
Linclust selects only one centroid per k-mer and lets the centroid recruit sequences sharing the same k-mer.
Sequences that fails to be recruited by the centroid remain as singletons.
Thus, Linclust is not sufficiently sensitive.
FgClust is significantly faster than MMSeqs2 especially at any clustering cutoff of high sequence similarity.
FgClust is significantly more scalable than CD-HIT and kClust. 
In fact, CD-HIT is characterized by slow and super-linear runtime especially at 50\% intra-cluster similarity.
CD-HIT compares each query input sequence with each target input sequence that shares at least one k-mer with the query input sequence.
kClust compares each query input sequence with each target input sequence that has at least one k-mer similar to any k-mer in the query input sequence.
The probability that two sequences possess similar k-mers by random chance is relatively constant and thus does not depend on the number of input sequences.
Thus, as the number of input sequences increases linearly, the number of pairwise comparisons triggered by random chance increases quadratically.
Thus, the runtime of CD-HIT and kClust is asymptotically quadratic with respect to input size.
Longer k-mer significantly reduces the probability that two sequences share the same longer k-mer by random chance.
Thus, longer k-mer implies that more input sequences are required to trigger the quadratic runtime of CD-HIT.
Indeed, \cref{fig:uniref} shows that the runtime of CD-HIT with five million sequences as input is roughly quadratic at 50\% sequence-identity cutoff but still roughly linear at 70\% or more sequence-identity cutoff.
FgClust and MMSeqs2 use longer k-mers for larger number of input sequences to maintain linear expected runtime with respect to the number of input sequences.
%Thus, only FgClust is useful in practice at 50\% intra-cluster similarity.

\begin{figure}%[!htbp]
	\centering
	\begin{tabular}{c c}
		\begin{tikzpicture}
		\begin{axis}[very thick,grid=both,
		width=0.475\textwidth,height=0.555\textwidth,
		mark options={solid},
		ymax=7,%xmax=1.1e8,
		%ymode=log,
		xlabel=Number of sequences,
		ylabel={Average cluster size (i.e. sensitivity)},
		legend columns=4,
		transpose legend,
		legend entries={FgClust~~,
			Linclust~~,
			MMSeqs2~~,
			CD-HIT~~,
			kClust~~,
			sim=50\%,sim=70\%,sim=90\%},
		legend pos=north west]
		\addlegendimage{,color=Red}
		\addlegendimage{dashed,color=Orange}
		\addlegendimage{dotted,color=Green}
		\addlegendimage{dash dot,color=Blue}
		\addlegendimage{dash dot dot,color=Magenta}
		\addlegendimage{only marks,mark=square}
		\addlegendimage{only marks,mark=o}
		\addlegendimage{only marks,mark=x}
		
		\addplot[color=Red,mark=square] coordinates {
			(1306318        , 1306318       / 458303)
			(4910948        , 4910948       / 1473070)
			(11659891       , 11659891      / 3144453)
			(33613081       , 33613081      / 7306576)
			(94756963       , 94756963      / 15630526)
		}; %FgClust 50
		\addplot[color=Red,mark=o] coordinates {
			(1306318        , 1306318       / 615387)
			(4910948        , 4910948       / 2097994)
			(11659891       , 11659891      / 4625378)
			(33613081       , 33613081      / 10989844)
			(94756963       , 94756963      / 24032649)
		}; %FgClust 70
		\addplot[color=Red,mark=x] coordinates {
			(1306318        , 1306318       / 851325)
			(4910948        , 4910948       / 3168436)
			(11659891       , 11659891      / 7221652)
			(33613081       , 33613081      / 18798319)
			(94756963       , 94756963      / 44723337)
		}; %FgClust 90
		
		\addplot[dashed,color=Orange,mark=square] coordinates {
			( 1306318,       1306318/       725566    )
			( 4910948,       4910948/       2562086   )
			(11659891,      11659891/       5847706   )
			(33613081,      33613081/       14766033        )
			(94756963,      94756963/       35983786        )
		}; %Linclust 50
		\addplot[dashed,color=Orange,mark=o] coordinates {
			( 1306318,       1306318/       819293    )
			( 4910948,       4910948/       3000298   )
			(11659891,      11659891/       6889416   )
			(33613081,      33613081/       17768118        )
			(94756963,      94756963/       43908412        )
		}; %Linclust 70
		\addplot[dashed,color=Orange,mark=x] coordinates {
			( 1306318,       1306318/       962908    )
			( 4910948,       4910948/       3625681   )
			(11659891,      11659891/       8306445   )
			(33613081,      33613081/       21974288        )
			(94756963,      94756963/       54672623        )
		};
		
		\addplot[dotted,color=Green,mark=square] coordinates {
			( 1306318,       1306318/       516052    )
			( 4910948,       4910948/       1670691   )
			(11659891,      11659891/       3611539   )
			(33613081,      33613081/       8247496 )
			(94756963,      94756963/       17763784        )
		}; % mmseqs2 50
		\addplot[dotted,color=Green,mark=o] coordinates {
			( 1306318,       1306318/       666575    )
			( 4910948,       4910948/       2358569   )
			(11659891,      11659891/       5244463   )
			(33613081,      33613081/       12622515        )
			(94756963,      94756963/       27872093        )
		};
		\addplot[dotted,color=Green,mark=x] coordinates {
			( 1306318,       1306318/       906871    )
			( 4910948,       4910948/       3415601   )
			(11659891,      11659891/       7874593   )
			(33613081,      33613081/       21060831        )
			%(94756963,      94756963/       77117011       ) % timeout
		};
		
		\addplot[dash dot,color=Blue,mark=square] coordinates {
			( 1303982 , 1303982 / 547396 )
			( 4908596 , 4908596 / 1818516 )
		};
		\addplot[dash dot,color=Blue,mark=o] coordinates {
			( 1303982 , 1303982 / 698797 )
			( 4908596 , 4908596 / 2532809 )
			( 11656604 , 11656604 / 5671408 )
			( 33606888 , 33606888 / 13921644 )
			( 94744006 , 94744006 / 31180026 )
		};
		\addplot[dash dot,color=Blue,mark=x] coordinates {
			( 1303982 , 1303982 / 878273 )
			( 4908596 , 4908596 / 3329592 )
			( 11656604 , 11656604 / 7627716 )
			( 33606888 , 33606888 / 20175146 )
			( 94744006 , 94744006 / 49205865 )
			
		};
	
		\addplot[dash dot dot,color=Magenta,mark=square] coordinates {
			( 1303982 , 1303982 / 572347 )
			( 4908596 , 4908596 / 1924257 )
		};
		\addplot[dash dot dot,color=Magenta,mark=o] coordinates {
			( 1303982 , 1303982 / 705456 )
			( 4908596 , 4908596 / 2552951 )
			( 11656604 , 11656604 / 5713855 )
		};
		\addplot[dash dot dot,color=Magenta,mark=x] coordinates {
			( 1303982 , 1303982 / 930527 )
			( 4908596 , 4908596 / 3556609 )
			( 11656604 , 11656604 / 8250898 )
		};
		\end{axis}
		\end{tikzpicture}
		&
		\begin{tikzpicture}
		\begin{axis}[very thick,grid=both,
		width=0.475\textwidth,height=0.555\textwidth,
		mark options={solid},
		%xmode=log,ymode=log,
		ymax=3600*50/1.5,%xmax=1.1e8,
		xlabel=Number of sequences,
		ylabel=Wall-clock runtime in seconds,
		legend columns=4,
		transpose legend, 
		legend entries={FgClust~~,
			Linclust~~,
			MMSeqs2~~,
			CD-HIT~~,
			kClust~~,
			sim=50\%,sim=70\%,sim=90\%},
		legend pos=north west
		]
		\addlegendimage{,color=Red}
		\addlegendimage{dashed,color=Orange}
		\addlegendimage{dotted,color=Green}
		\addlegendimage{dash dot,color=Blue}
		\addlegendimage{dash dot dot,color=Magenta}
		\addlegendimage{only marks,mark=square}
		\addlegendimage{only marks,mark=o}
		\addlegendimage{only marks,mark=x}
		
		\addplot[color=Red,mark=square] coordinates {
			( 1306318,      216.03)
			( 4910948,      923.48)
			(11659891,      2554.06)
			(33613081,      7305.12)
			(94756963,      19434.67)
		};
		\addplot[color=Red,mark=o] coordinates {
			( 1306318,      164.24)
			( 4910948,      712.02)
			(11659891,      2151.47)
			(33613081,      6858.06)
			(94756963,      15651.55)
		};
		\addplot[color=Red,mark=x] coordinates {
			( 1306318,      105.10)
			( 4910948,      446.33)
			(11659891,      1578.28)
			(33613081,      4595.46)
			(94756963,      12873.48)
		};
	
		\addplot[dashed,color=Orange,mark=square] coordinates {
			( 1306318,      63.24)
			( 4910948,      259.20)
			(11659891,      600.11)
			(33613081,      1859.28)
			(94756963,      6444.66)
		}; %linclust 50
		\addplot[dashed,color=Orange,mark=o] coordinates {
			( 1306318,      66.58)
			( 4910948,      278.11)
			(11659891,      652.31)
			(33613081,      2013.65)
			(94756963,      6639.85)
		};
		\addplot[dashed,color=Orange,mark=x] coordinates {
			( 1306318,      73.96)
			( 4910948,      334.20)
			(11659891,      744.64)
			(33613081,      2270.75)
			(94756963,      6698.25)
		};
		
		\addplot[dotted,color=Green,mark=square] coordinates {
			( 1306318,      603.10)
			( 4910948,      2898.67)
			(11659891,      8230.45)
			(33613081,      26272.73)
			(94756963,      77837.47)
		};
		\addplot[dotted,color=Green,mark=o] coordinates {
			( 1306318,      737.74)
			( 4910948,      4098.65)
			(11659891,      11068.39)
			(33613081,      35445.09)
			(94756963,      99781.83)
		};
		\addplot[dotted,color=Green,mark=x] coordinates {
			( 1306318,      905.05)
			( 4910948,      6154.68)
			(11659891,      18524.44)
			(33613081,      77145.61)
			%(94756963,timeout)
		};
		
		\addplot[dash dot,color=Blue,mark=square] coordinates {
			( 1306318,      5766.21)
			( 4910948,      75911.85)
			%(11659891,timeout)
			%(33613081,timeout)
			%(94756963,timeout)
		};
		\addplot[dash dot,color=Blue,mark=o] coordinates {
			( 1306318,      264.31)
			( 4910948,      929.93)
			(11659891,      2062.60)
			(33613081,      7563.33)
			(94756963,      28834.18)
		};
		\addplot[dash dot,color=Blue,mark=x] coordinates {
			( 1306318,      311.15)
			( 4910948,      955.40)
			(11659891,      2315.58)
			(33613081,      9395.35)
			(94756963,      43880.61)
		};
	
		\addplot[dash dot dot,color=Magenta,mark=square] coordinates {
			( 1303982 , 4378.45 )
			( 4908596 , 32820.26 )
		};
		\addplot[dash dot dot,color=Magenta,mark=o] coordinates {
			( 1303982 , 2447.86 )
			( 4908596 , 19014.50 )
			( 11656604 , 75912.68 )
		};
		\addplot[dash dot dot,color=Magenta,mark=x] coordinates {
			( 1303982 , 2597.88 )
			( 4908596 , 16724.53 )
			( 11656604 , 75284.21 )
		};
		\end{axis}
		\end{tikzpicture}
	\end{tabular}
	\caption{
		UniRef100-2.0, 
		UniRef100-12.0,
		UniRef100-2011-01, 
		UniRef100-2014-01, and 
		UniRef100-2017-01 
		are five versions of the UniRef100 database and capture the growth of UniRef100 from July 2004 to January 2017 \citep{suzek2007uniref}.
		These five versions have \SI{1306318}{}, \SI{4910948}{}, \SI{11659891}{}, \SI{33613081}{}, and \SI{94756963}{} sequences, respectively \citep{suzek2007uniref}.
		We ran each program on each UniRef100 version with each intra-cluster similarity threshold to generate each set of clusters.
		Cluster quality is not assessed due to the lack of ground truth. 
		Each program times out after running for \SI{180000}{} seconds.
		\label{fig:uniref}
	}
\end{figure}

\begin{figure}%[!htbp]
	\centering
		\begin{tabular}{c c}
			\begin{tikzpicture}
			\begin{axis}[very thick,grid=both,
			mark options={solid},
			width=0.475\textwidth,
			height=0.385\textwidth,
			ymax=2000,
			xlabel=Number of clusters,
			ylabel=Number of corrupted clusters]
			\addplot[color=Red,mark=square] coordinates {
				(365172, 956)
				(516422, 738)
				(755086, 510)
				(1066591, 248)
				(1282334, 71)
			};
			\addlegendentry{FgClust}
			\addplot[dashed,color=Orange,mark=square] coordinates {	
				(682422, 819)
				(806160, 726)
				(982978, 572)
				(1199664, 401)
				(1281061, 188)
			};
			\addlegendentry{Linclust}
			\addplot[dotted,color=Green,mark=square] coordinates {
				(389286, 962)
				(592144, 878)
				(843097, 670)
				(1128443, 462)
				(1253416, 260)
			};
			\addlegendentry{MMSeqs2}
			\addplot[dash dot,color=Blue,mark=square] coordinates {
				(471396, 1894)
				(713570, 936)
				(976870, 558)
				(1252062, 317)
				(1284604, 135)
			};
			\addlegendentry{CD-HIT}
			\addplot[dash dot dot,color=Magenta,mark=square] coordinates {
				(504834,944)
				(697636,794)
				(947935,578)
				(1221908,331)
				(1283087,141)
			};
		``  \addlegendentry{kClust}
			\end{axis}
			\draw[->,very thick](2,1.5)--(0.5,0.5)node
			[midway,below,sloped]{better};
			\end{tikzpicture}
			&
			\begin{tikzpicture}
			\begin{axis}[very thick,grid=both,
			mark options={solid},
			width=0.475\textwidth,
			height=0.385\textwidth,
			ymax=5000,
			xlabel=Number of clusters,
			ylabel=Number of corrupted members]
			\addplot[color=Red,mark=square] coordinates {
				(365172, 1642)
				(516422, 1177)
				(755086, 688)
				(1066591, 282)
				(1282334, 77)
			};
			\addlegendentry{FgClust}
			\addplot[dashed,color=Orange,mark=square] coordinates {
				(682422, 1501)
				(806160, 1111)
				(982978, 749)
				(1199664, 445)
				(1281061, 193)
			};
			\addlegendentry{Linclust}
			\addplot[dotted,color=Green,mark=square] coordinates {
				(389286, 2429)
				(592144, 1602)
				(843097, 1037)
				(1128443, 561)
				(1253416, 294)
			};
			\addlegendentry{MMSeqs2}
			\addplot[dash dot,color=Blue,mark=square] coordinates {
				(471396, 4126)
				(713570, 1549)
				(976870, 705)
				(1252062, 342)
				(1284604, 139)
			};
			\addlegendentry{CD-HIT}
			\addplot[dash dot dot,color=Magenta,mark=square] coordinates {
				(504834,2230)
				(697636,1452)
				(947935,804)
				(1221908,379)
				(1283087,149)
			};
			\addlegendentry{kClust}
			\end{axis}
			\draw[->,very thick](2,1.5)--(0.5,0.5)node
			[midway,below,sloped]{better};
			\end{tikzpicture}
		\end{tabular}
	\caption{Results of clustering Pfam-A-seed version 31.0 \citep{finn2016pfam}.
		On each plotted curve, the five marks from top left to bottom right correspond to the five sequence-similarity cutoffs of 50\%, 60\%, 70\%, 80\%, and 90\%, respectively.
		A cluster is corrupted if and only if at least one member in the cluster is corrupted.
		A cluster member is corrupted if and only if the member belongs to a Pfam family that the representative of the cluster does not belong to.
		The runtime of each program is too short to measure wall-clock time and scalability.
		\label{fig:pfam}
	}
\end{figure}
We assessed the sensitivity and specificity of FgClust by using manually curated data.
We downloaded the manually curated seed A dataset from Pfam version 31.0 \citep{finn2016pfam}.
We ran each clustering algorithm on this dataset.
A corrupted cluster contains at least two sequences that belong to two different Pfam families.
A corrupted cluster member belongs to a Pfam family that the representative of this cluster does not belong to.
A more sensitive clustering algorithm generates fewer clusters.
A more specific clustering algorithm generates fewer corrupted clusters and fewer corrupted cluster members.
\Cref{fig:pfam} shows that FgClust generates much fewer number of corrupted clusters and cluster members given the same number of clusters generated.
Thus, FgClust achieves the best sensitivity-specificity trade-off.
CD-HIT has the worst sensitivity-specificity trade-off at low sequence identity presumably because inferring biological relatedness from only low sequence identity is highly error-prone.
FgClust normalizes edit-similarity with respect to sequence length.
Linclust, MMSeqs2, and kClust use e-value in addition of sequence identity.
Thus, FgClust, Linclust, MMSeqs2, and kClust do not suffer from such drop in sensitivity-specificity trade-off at low sequence similarity.
Linclust, MMSeqs2, and kClust use iterative, profile-based clustering strategy and can thus merge similar clusters into one single cluster.
A false-positive merging step corrupts only one cluster but can corrupt multiple cluster members.
Thus, Linclust, MMSeqs2, and kClust generate high numbers of corrupted cluster members compared with the numbers of corrupted clusters.

\subsection{Evaluation on nucleotide databases}

\begin{figure}%[!htbp]
	\centering
\begin{tabular}{c c}
\begin{tikzpicture}
\begin{axis}[very thick,grid=both,
mark options={solid},
width=0.475\textwidth,
height=0.365\textwidth,
ymax=80,%ymode=log,
xlabel=Number of clusters,
ylabel=Number of corrupted clusters]
\addplot[color=Red,mark=square] coordinates {
%(4963, 1458)
(7156, 32)
(11828, 11)
(20754, 14)
(34117, 11)
};
\addlegendentry{FgClust}
\addplot[dotted,color=Green,mark=square] coordinates {
%(7509, 126)
(8929, 69)
(11978, 43)
(18085, 38)
(27963, 46)
};
\addlegendentry{VSEARCH}
\addplot[dash dot,color=Blue,mark=square] coordinates {
	(15074, 36)
	(26608, 21)
};
\addlegendentry{CD-HIT-EST}
\end{axis}
\draw[->,very thick](2,1.5)--(0.5,0.5)node
[midway,below,sloped]{better};
\end{tikzpicture}
&
\begin{tikzpicture}
\begin{axis}[very thick,grid=both,
mark options={solid},
width=0.475\textwidth,
height=0.365\textwidth,
ymax=200,%ymode=log,
xlabel=Number of clusters,
ylabel=Number of corrupted members]
\addplot[color=Red,mark=square] coordinates {
%(4963, 3782)
(7156, 171)
(11828, 19)
(20754, 18)
(34117, 14)
};
\addlegendentry{FgClust}
\addplot[dotted,color=Green,mark=square] coordinates {
%(7509, 1958)
(8929, 186)
(11978, 109)
(18085, 84)
(27963, 67)
};
\addlegendentry{VSEARCH}
\addplot[dash dot,color=Blue,mark=square] coordinates {
	(15074, 100)
	(26608, 44)
};
\addlegendentry{CD-HIT-EST}
\end{axis}
\draw[->,very thick](2,1.5)--(0.5,0.5)node
[midway,below,sloped]{better};
\end{tikzpicture}
\end{tabular}
\caption{Results of clustering Rfam-seed version 12.3 \citep{nawrocki2014rfam}.
	On each plotted curve, the four marks from left to right correspond to the four sequence-similarity cutoffs of 60\%, 70\%, 80\%, and 90\%, respectively. CD-HIT-EST does not run with any sequence-similarity cutoff of less than 80\%.
	A cluster is corrupted if and only if at least one member in the cluster is corrupted.
	A cluster member is corrupted if and only if the member belongs to an Rfam family that the representative of the cluster does not belong to.
	The runtime of each program is too short to measure wall-clock time and scalability.
	\label{fig:rfam}
}
\end{figure}
We assessed the sensitivity and specificity of FgClust by using manually curated nucleotide data. 
We downloaded the seed dataset from Rfam version 12.3 \citep{nawrocki2014rfam}.
We ran FgClust commit 93c3a6d9, VSEARCH v2.3.4\_linux\_x86\_64 \citep{rognes2016vsearch}, and CD-HIT-EST version 4.6 \citep{fu2012cd} on this dataset.
Evaluation criteria on Rfam and Pfam are similar.
\Cref{fig:rfam} shows that FgClust generates much fewer clusters given the same number of corrupted clusters and much fewer corrupted clusters given the same number of clusters.
Thus, FgClust is significantly more sensitive at the same specificity and significantly more specific at the same sensitivity.
Thus, FgClust performs the best for the Rfam dataset.

\section{Conclusion}

We developed FgClust, a novel algorithm for clustering biological sequences.
FgClust is more sensitive, more specific, and faster than all other published clustering algorithms, except that Linclust is two times faster but also generates up to more than 130\% more clusters than FgClust.
We observed that greedy incremental update may not select the optimal centroid during each incremental update.
Thus, FgClust detects sufficient number of sequence pairs such that, in each pair, the first can represent the second.
Then, FgClust uses greedy set cover to cluster all sequences based on such pairings.
We observed that there are too many short words in a protein sequence.
Thus, FgClust uses min-hash values instead of short words.
We observed that sequence identity is not sufficiently correlated with biological relatedness and requires the time-consuming computation of alignment.
Thus, FgClust uses edit-similarity instead of sequence identity.
%Edit-similarity is defined as one minus the following: 
%	number of single-character edits to change a member sequence into a substring of the centroid sequence, divided by the length of the member sequence.

In the future, we will construct a Hidden Markov Model (HMM) for each cluster generated by FgClust and assess the quality of such HMMs.
Moreover, we will apply the techniques used in FgClust to other problems, such as metagenomic-sequence classification, chimera detection, and detection of conserved protein domains.


\bibliographystyle{plainnat}
%\bibliographystyle{unsrtnat}
\bibliography{clust}

\iffalse

\subsection{Reduction of greediness in greedy incremental update}

Greedy incremental update may not be optimal.
For example, suppose we would like to cluster the following sequences at 65\% sequence identity:
ABXXEFGHIJ, 
ABXXEFXXI, and
BCDEFXXIJ.
In this case, 65\% sequence identity corresponds to 6 inclusive matches, or equivalently, exclusive edit distance of 4.
Then, greedy incremental update would pick ABXXEFGHIJ as the centroid of the first cluster, 
assign ABXXEFXXI to the first cluster because ABXXEFXXI is 3 edit distance away from ABXXEFGHIJ, 
and pick BCDEFXXIJ as the centroid of the second cluster because BCDEFXXIJ is 4 edit distance away from ABXXEFGHIJ.
However, if ABXXEFXXI is picked as the centroid of the first cluster, then both ABXXEFGHIJ and BCDEFXXIJ would be assigned to the first cluster. 

Instead of performing clustering while iterating through all sequences, we can perform clustering after computing the pairwise sequence identity of all sequences. 
In this case, sequence clustering is formulated as the dominating set problem, which is a special type of the set-cover problem. 
In this dominating set problem, an edge from a first vertex to a second vertex means that the first corresponding biological sequence can represent the second corresponding biological sequence. 

However, we observed that, for biological databases such as uniprot, the number of edges is orders of magnitude more numerous than the number of vertices. Thus, exhaustive generation of all edges requires substantial computational resources.
At the same time, such biological databases induce graphs characterized by rare cliques of large sizes, presumably because some biomolecules are over-represented due to their biological importance and/or abundance.
Thus, if an unvisited sequence is already represented by many other visited sequences that approximately form a clique, then this unvisited sequence is unlikely to form a new cluster that can contain members outside of this clique. 
Thus, in this case, we do not determine the sequences that this new sequence can represent, and thus do not generate any edge starting from the vertex corresponding to this new sequence. 
Thus, the resulting graph is incomplete but does not substantially affect the optimality of the resulting dominating set problem.

Then, we the greedy set-cover algorithm to solve the dominating set problem on the incomplete graph.
In addition of producing a solution that consists of a set of sequences, 
our greedy set-cover algorithm makes sure that each sequence is only represented by the best representative sequence.
For example, if sequence A can be represented by either representative sequences B or C but A is more similar to C,
then A will be clustered with C.
Our greedy set-cover algorithm uses linear memory and runtime and is highly optimized for memory usage.

\subsection{Throw-away of abundant and uninformative long words}

Some biological sequences contain uninformative region.
For example, a peptide sequence may consist of conserved regions and hypervariable regions.
The higher the sequence identity threshold is, the less informative the conserved region is.
Thus, two sufficiently dissimilar sequences can still share the same long word in the uninformative region.
If we use a naive long-word filter, then we will initiate a computationally more expensive comparison between these two sequences that share at least one uninformative long word.
An uninformative long word slows down the clustering process only if many sequences share this long word.
Thus, we rank all long words by percentile in increasing order of abundance.
For each long word that is longer than expected, we used hashed signatures, which are similar to short words in terms of function but are much less computationally intensive to work with, to estimate the sequence identity between some random pairs of sequences sharing this long word.
If the frequency that the estimated sequence identity meets the user-defined threshold is below a certain threshold,
then we throw-away the long word.
A throw-away long word does not initiate further computationally more expensive comparison between two sequences that share this long word.
Thus, computation time can be saved by removing uninformative long words without much sacrifice in sensitivity.
To reduce memory usage, we use the hash values of long words instead of the long words themselves, which is similar to the technique used in \citet{steinegger2017Linclust}.

\subsection{Reduction of short words into hashed signature}

A typical protein sequence consists of about 400 amino acids.
Thus, two protein sequences typically have two sets of 400 short words each.
However, if we uniformly, randomly, and independently (URI) subsample a small number of short words in each set of short words, then the subsampled short words can still work reasonably well. 
Nonetheless, we still need to maximize the collision rate between two sets of URI subsampled short words.
We used a technique similar to min-hash to achieve such URI subsampling while maximizing such collision rate.
In brief, each short word is hashed into a 16-bit unsigned integer.
The 31 smallest hash values form the signature of the sequence.
When we need to compare two sequences, we first compare their signatures.
If their signatures do not share a certain number of hash values in common, then we stop any further comparison between the two sequences. 
Otherwise, we proceed to compare the two sequences by using a computationally more expensive method.
Instead of comparing 400 short words, we only have to compare 31 hash values.

A typical nucleotide sequences is usually three times as long as a typical protein sequence.
Thus, the reduction of short words into signature is even more effective for nucleotide sequences.

One-to-many query-to-target sequence comparison is needed in sequence clustering. 
Similar to the technique used in \citet{li2006cd}, we sort, in descending order, the targets according to their number of shared hash values with the query before iterating through the targets. 
Similar to the technique used in \citet{edgar2010search}, we keep track of the number of failed attempts, or equivalently number of false-positive hits, when iterating through targets.
In addition, we keep track of the number of successful attempts, or equivalently number of true-positive hits, while iterating through targets.
Before iterating through the sorted targets, we initialize the number of remaining attempts to a positive integer.
If an attempt fails, we decrement the number of remaining attempts by one.
If an attempt succeeds, we increment the number of remaining attempts by a positive integer.
If the number of attempts becomes zero, then we stop iterating through the targets, because the not-yet-iterated remaining targets are not likely to be true positive hits.
The idea is that the ratio of success to failure should be above a certain threshold given a Bayesian prior of such ratio.

\subsection{Use of edit similarity instead of sequence identity}

Pairwise sequence identity is defined as the number of identical residues in a pairwise sequence alignment, divided by either the length of the alignment or the length of the shortest sequence. 
Unless explicitly stated otherwise, we assume that the sequence alignment used to generate sequence identity is the optimal alignment in terms of alignment score.

We developed a new measure of similarity between two sequences called edit-similarity.
The edit-similarity between a query and a target is defined as: the length of the target minus the number of edits required such that the target is a substring of the query, divided by the length of the target.
In terms of definition, edit-similarity is almost identical to the similarity in table 1 of \cite{vsovsic2017edlib}, 
except that edit-similarity uses target length as divisor whereas the similarity in \cite{vsovsic2017edlib} uses min(query-length, target-length) as the divisor. 
For example, the edit-similarity between \texttt{ACGGT} and \texttt{ATGG} is (4-1)/4, and the edit-similarity between \texttt{ATGG} and \texttt{ACGGT} is (5-2)/5.
The query is said to cover the target if the edit-similarity between the query and the target is higher than a predefined threshold.

Edit-distance requires much less computational time than pairwise alignment with substitution matrix, gap opening penalty, and gap extension penalty \cite{vsovsic2017edlib}. 
At first glance, it seems that we would lose some information by not computing pairwise alignment. 
However, it turns out that edit-similarity is biologically more relevant than sequence identity.
In the next two paragraphs, we will heuristically explain why edit-similarity is biologically more relevant.
In \ref{fig:specificity}, we will show that edit-similarity is more correlated with protein structural similarity than sequence identity.

Let \(s_1\) and \(s_2\) be two sequences such that \(s_1\) is longer than \(s_2\).
Let \(I(s_1, s_2)\) be the sequence identity between \(s_1\) and \(s_2\).
Let \(E(s_1, s_2)\) be the edit-similarity between \(s_1\) and \(s_2\).
If \(I(s_1, s_2) < E(s_1, s_2)\), then the alignment used to generate \(I(s_1, s_2)\) has fewer matches of identical residues, but more alignment score, than the alignment used to generate \(E(s_1, s_2)\).
Thus, the alignment used to generate \(I(s_1, s_2)\) must have in general more conserved amino-acid substitutions than the alignment used to generate \(E(s_1, s_2)\) in order to produce higher alignment score with less sequence identity.
However, the more conserved amino-acid substitutions from \(I(s_1, s_2)\) imply that \(I(s_1, s_2)\) probably underestimates the true biological similarity between \(s_1\) and \(s_2\) anyway, because more conserved amino-acid substitutions have bigger impact on protein structures and functions.
Thus, \(E(s_1, s_2)\) measures better the true biological similarity between \(s_1\) and \(s_2\) than \(I(s_1, s_2)\) even though the alignment used to compute \(I(s_1, s_2)\) can provide a white-box explanation for the relationship between \(s_1\) and \(s_2\).
For example, suppose \(s_1 = \texttt{AIAISSRRSSWWW}\) and \(s_2 = \texttt{AIAIWWW}\), 
and suppose we use blosum62 matrix for computing \(I(s_1, s_2)\).
In blosum62, the match reward for \texttt{W} is 11, and the match reward for both \texttt{A} and \texttt{I} is 4.
Thus, \(I(s_1, s_2) = 4/7\) because the           chunk \texttt{AIAI} is shared between \(s_1\) and \(s_2\).
but \(E(s_1, s_2) = 3/7\) because the conserved chunk \texttt{WWW}  is shared between \(s_1\) and \(s_2\).
However, since \texttt{W} is so conserved, \(3/7\) is an underestimates of the extend of biological relationship between \(s_1\) and \(s_2\).
Thus, \(4/7\) is closer to such extend of biological relationship.

Edit similarity is supposed to be uncorrelated with conservation of amino-acid residues, but sequence identity can be negatively correlated with conservation of amino-acid residues.
In addition, edit similarity considers deletion of \(s_1\) in \(s_2\), whereas sequence identity ignores deletion of \(s_1\) in \(s_2\).
For example, the edit similarity between \texttt{AAACGGG} and \texttt{AAAGGG} is (6-1)/6, but the corresponding sequence identity is 1. Thus, edit similarity is supposed to be more informative than sequence identity if part of the longer sequence is deleted in the shorter sequence.

\fi

\end{document}
