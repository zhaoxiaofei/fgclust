\documentclass[]{article}

\usepackage[margin=1in]{geometry}

\usepackage{booktabs}
\usepackage{cleveref}


%\usepackage{pgfplotstable,booktabs}
%\usepackage{filecontents}

%\usepackage{csvsimple}

\usepackage{natbib}
%\bibliographystyle{IEEEtranN}

%opening
\title{}
\author{}

\begin{document}

\maketitle

\begin{abstract}

\end{abstract}

\section{Introduction}

Sequence clustering is a classic problem in biology.
Clustering of complete biological sequences generates de-novo taxonomy and reduces the redundancy of biological database.
%Clustering of short reads produced by sequencers can detect and correct sequencing error.

We developed a new sequence-clustering algorithm that can scale to hundred of millions protein sequences.
Our algorithm is more sensitive, more specific, and faster than known published sequence clustering algorithms.
%Our algorithm can generate better de-novo taxonomy, 

\section{Related works}

Clustering of biological sequences has a long history.
\Citet{holm1998removing} observed that two sufficiently long protein sequences that share no common decapeptide must have at most 90\% sequence identity.
Based on this observation, \citet{holm1998removing} developed a method called nrdb90 that clusters protein sequences at 90\% sequence identity.
However, nrdb90 is slow and works only for sequence identity of at least 90\%.
\Citet{li2001clustering} observed that two protein sequences of lengths \(L_1\) and \(L_2\) must share at least \(x\) peptides of length \(y\) in order to share at least \(z\)\% sequence identity, 
	where \(L_1\), \(L_2\), \(x\), \(y\), and \(z\) are mathematically interdependent variables.
\Citet{li2001clustering} therefore generalized the decapeptide filter into short-word filter.
Based on this generalization, \cite{li2001clustering} developed a method called CD-HI that clusters protein sequences at 70\% or more sequence identity.
\Citet{li2001clustering} introduced the notion of greedy incremental update, where sequences are longest-first sorted and each sequence either belongs to an already formed cluster or forms a new cluster. 
Since then, nearly all clustering methods used greedy incremental update, so we will assume such unless explicitly stated otherwise.
CD-HI is both significantly faster and can cluster at lower sequence identity than nrdb90 without compromising neither sensitivity nor specificity.
However, the exponential increase in the size of a typical protein database such as nr even made CD-HI too slow to be practical.
\Citet{li2002tolerating} extended the work of \citet{li2001clustering} by probabilistically filtering out sequence pairs that are likely to share less than a certain sequence-identity cutoff.
\Citet{li2002tolerating} observed that two protein sequences of lengths \(L_1\) and \(L_2\) are not necessarily , but likely, to share at least \(x\) peptides of length \(y\) in order to share at least \(z\)\% sequence identity.
Based on this extension, \citet{li2002tolerating} developed a method called CD-HIT that clusters protein sequences at 50\% or more sequence identity. 
At the same sequence-identity cutoff, CD-HIT produces 0.4\% more clusters than but is about 100 times faster than CD-HI.
\Citet{li2006cd} observed that the algorithm in CD-HIT can be used for clustering nucleotide sequences and for comparing two biological databases.
\Citet{fu2012cd} used OpenMP to parallelize CD-HIT.

\Citet{edgar2010search} developed a method called usearch which performs database search by sequence identity. 
In addition of using the short-word filter used by CD-HIT, usearch only searches a fixed maximum number of top hit target sequences per query sequence.  
\Citet{edgar2010search} also developed uclust which clusters biological sequences using the distance computed by usearch.
Usearch and uclust are both closed-source commercial programs, so \citet{rognes2016vsearch} developed vsearch which is open-source and similar to usearch and uclust in terms of functionality and performance.

Clustering of short reads produced by Next-Generation Sequencing (NGS) is also an ongoing research topic.
\Citet{zorita2015starcode} developed starcode, an algorithm for clustering sequences at high global similarity cutoff based edit distance.
Starcode is especially useful for detection and correction of sequencing errors. 

\section{Novel key ideas}

In greedy incremental update, a iterated sequence either forms a new cluster or is assigned to an existing cluster.
However, such clustering decision can result in suboptimal solution.
Instead, we delay the clustering decision until sufficient sequences are iterated over.
Then, we make clustering decisions using an algorithm that is less greedy than the greedy incremental update.
This reduction in greediness increases sensitivity.
We implemented a memory-efficient version of the greedy set cover algorithm,
	where each representative sequence represents and covers its member sequences.

In short-word filter, the similarity between two sequences is estimated by counting their common short words.
However, a typical biological sequence has hundreds of short words.
Instead, we transform short words into hash values and select a fixed number of lowest hash values.
Then, we use the lowest hash values as short words, similar to the technique of minhash.
This reduction in short words reduces runtime.
We implemented a version of rolling hash that produces pseudorandom hash values.

Sequence identity is the number of matches divided by the length of the shorter sequence in an alignment.
Usually, blosum62 matrix with linear gap model is used to compute such alignment.
However, such computation of alignment is time-consuming.
Moreover, deletions in the longer sequence are ignored.
Therefore, normalization by the length of the shorter sequence can overestimate the true biological similarity.
Conservation of biological function requires smaller number of matches of conserved residues than matches of non-conserved residues. 
However, smaller number of matches decreases sequence identity.
Unfortunately, substitution matrices such as blosum62 tend to produce matches of conserved residues.
Thus, sequence identity computed with a substitution matrix can underestimate the true biological similarity.
Instead of using sequence identity to estimate true biological similarity, we used edit-similarity.
The edit-similarity between a query and a target is defined as follows: 
	the length of the target minus the minimum number of single-character edits required such that the target is a substring of the query, divided by the length of the target.
Then, we use edit-similarity as sequence identity.
Edit-similarity takes less time to compute \cite{vsovsic2017edlib} than sequence identity.
Moreover, edit-similarity is more correlated with true biological similarity than sequence identity \cref{table:pdb,table:pfam}.
Therefore, the use of edit-similarity instead of sequence identity improves sensitivity, specificity, and runtime.
We used the library implemented by \citet{vsovsic2017edlib} to compute edit-similarity.

In addition of using the previously mentioned novel techniques, we also developed variants of existing sequence-search techniques.
Given a query sequence, our algorithm searches only database sequence that shares at least one informative long word with the query sequence.
A long word is a kmer and is represented by its hash value.
Our algorithm ignores uninformative and abundant long words to improve runtime.
A long word is uninformative if and only if the sequences that share this long word are usually dissimilar according to their min-hash signatures.
Therefore, two sequences sharing only uninformative and abundant long words will be ignored in sequence search.
Our algorithm uses the amino-acid alphabet reduction suggested by \cite{murphy2000simplified} to improve sensitivity.
Long words and min-hash signatures are computed with the reduced alphabet, but edit-similarity is computed with the unreduced alphabet.
Our algorithm sorts in descending order target candisdates by the number of min-hash values shared between the query and each target candidate.
Our algorithm initializes and then keeps track of a number of remaining attempts.
Each true/false-positive target candidate increases/decrease the number of remaining attempts.
The search terminates when the number of remaining attempts reaches zero, similar to the pruning used in \cite{edgar2010search}.

\section{Evaluation}

We compared our algorithm with CD-HIT version 4.6 and Linclust commit 91644c75.
Only the memory-limited 32-bit version of \citet{edgar2010search} is free and \citet{edgar2010search} is not open source.
Therefore, we omitted \citet{edgar2010search} in our evaluation.
We evaluated all clustering algorithms on a ``CentOS release 6.6'' server that runs on a 32-threads ``Intel(R) Xeon(R) CPU E5-2660 0 @ 2.20GHz''.

\begin{table}%[!htbp]
	\centering
	\caption{
		The sequences and structures of all monomeric proteins in PDB accessed in June 1st 2017 are given as input to each program. 
		Each program is run with each intra-cluster similarity threshold to generate each set of clusters.
		For each set of clusters, the number of clusters characterized by intra-cluster TM scores inclusively below each threshold is tabulated.
		The intra-cluster TM score of a cluster is the lowest TM score between the representative sequence in the cluster as template and each represented sequence in the cluster.}
	\begin{tabular}{l c c c c c c c c c c c}
		
		\toprule
		Program & intra-cluster & \multicolumn{10}{c}{Intra-cluster TM scores} \\
		& similarity & 0.1 & 0.2 & 0.3 & 0.4 & 0.5 & 0.6 & 0.7 & 0.8 & 0.9 & 1.0 \\
		\midrule
		
		mine     & 50 & 0 & 7 & 46 & 137 & 283 & 510 & 877 & 1403 & 2214 & 16575 \\
		linclust & 50 & 0 & 29 & 118 & 253 & 402 & 656 & 1032 & 1565 & 2368 & 16964 \\
		CD-HIT   & 50 & 0 & 40 & 138 & 280 & 438 & 694 & 1107 & 1631 & 2445 & 15712 \\
		
		mine     & 70 & 0 & 7 & 42 & 131 & 253 & 444 & 761 & 1228 & 1960 & 18010 \\
		linclust & 70 & 0 & 30 & 119 & 245 & 378 & 614 & 957 & 1446 & 2190 & 17828 \\
		CD-HIT   & 70 & 0 & 39 & 126 & 247 & 380 & 585 & 913 & 1390 & 2118 & 17668 \\
		
		mine     & 90 & 0 & 7 & 35 & 111 & 219 & 380 & 633 & 1022 & 1724 & 19400 \\
		linclust & 90 & 0 & 23 & 89 & 188 & 316 & 502 & 796 & 1221 & 1922 & 19298 \\
		CD-HIT   & 90 & 0 & 29 & 114 & 223 & 342 & 514 & 772 & 1160 & 1852 & 19194 \\
		
		\bottomrule
	\end{tabular}
	\label{table:pdb}
\end{table}

First, we assessed the specificity of our sequence-clustering algorithm using only experimentally verified data.
We downloaded all monomeric proteins with experimentally determined structures from PDB in June 1st 2017 \cite{bank1971protein}.
The sequence of each protein is extracted.
From these extracted sequences, every sequence-clustering algorithm produces a set of clusters.
Within each cluster, the template-modeling (TM) score between the representative sequence and each represented sequence is computed by TM-Align developed by \citet{zhang2005tm}.
The lowest such TM score within each cluster is extracted.
The number of such extracted TM scores below certain TM score thresholds are shown in \cref{table:pdb}.
The higher such extracted TM scores are, the more specific the clustering algorithm is. 
\Cref{table:pdb} shows that our algorithm produces the fewest number of clusters with low intra-cluster TM scores.
Therefore, our algorithm is more specific than other algorithms in terms of experimentally observed protein structures.

\begin{table}%[!htbp]
	\centering
	\caption{
		All sequences in a specified version of uniref are given as input to each program. 
		Each program is run with each intra-cluster similarity threshold to generate each set of clusters.
		Runtime is measured in minutes.
	}
	\begin{tabular}{l c c c c c c c}
		\toprule
		Program & intra-cluster & \multicolumn{2}{c}{uniref100-2011-01}
		& \multicolumn{2}{c}{uniref100-2014-01}
		& \multicolumn{2}{c}{uniref100-2017-01} \\ 
		& similarity    & cluster count & runtime
		& cluster count & runtime
		& cluster count & runtime \\
		\midrule
		mine     & 90 & 7539905 & 43 & 19864156 & 117 & 48113438 & 442 \\
		linclust & 90 & 8079020 & 11 & 21434130 & 35  & 53391467 & 109 \\
		CD-HIT   & 90 & 7627325 & 46 & 20173024 & 132 & 49200220 & 724 \\
		
		mine     & 70 & 5531553 & 36 & 13482152 & 127 & 29938650 & 563 \\
		linclust & 70 & 6192036 & 11 & 15548951 & 33  & 37011492 & 104 \\
		CD-HIT   & 70 & 5671370 & 41 & 13921545 & 110 & 31178816 & 525 \\
		
		mine     & 50 & 3911258 & 62 & 8991582  & 276 & 19288061 & 1443 \\
		linclust & 50 & 5114737 & 10 & 12535362 & 30  & 29461562  & 92 \\
		CD-HIT   & 50 & timeout & \(>\)5000 & timeout & \(>\)5000 & timeout & \(>\)5000 \\
		\bottomrule
	\end{tabular}
	\label{table:uniref}
\end{table}

Second, we assessed the sensitivity and runtime of our sequence-clustering algorithm.
We downloaded the three version of UniRef \cite{suzek2007uniref} shown in \cref{table:uniref}.
From each version of UniRef, we extracted protein sequences.
From these extracted sequences, every sequence-clustering algorithm produces a set of clusters.
The number of clusters produced by each algorithm and the runtime of each algorithm are listed in \cref{table:uniref}.
A more sensitive clustering algorithm produces less number of clusters.
\Cref{table:uniref} shows that our algorithm produces the least number of clusters.
Therefore, our algorithm is the most sensitive.
Moreover, \cref{table:uniref} shows that our algorithm is generally faster than CD-HIT.
Our algorithm is slower but significantly more sensitive than Linclust.
In fact, Linclust produces 50\% more clusters than our algorithm at 50\% intra-cluster similarity.
CD-HIT times out at 50\% intra-clustr similarity.
Therefore, only our algorithm is useful in practice at 50\% intra-cluster similarity.

\begin{table}%[!htbp]
	\centering
	\caption{Results of clustering Pfam-A.seed versin 31.0.
		A cluster is corrupted if and only if the cluster has at least two members that belong to different Pfam families.
		A cluster member is corrupted if and only if the member belongs to a Pfam family that the representative of the cluster does not belong to.
	}
	\begin{tabular}{l c c c c}
		\toprule
		Program & intra-cluster & 
		\multicolumn{3}{c}{numerical statistics for Pfam-A.seed} \\
		& similarity    & cluster & corrupted cluster & corrupted cluster member \\
		\midrule
		mine     & 90 & 1285018 & 111 & 114 \\
		linclust & 90 & 1281035 & 189 & 198 \\
		cd-hit   & 90 & 1284610 & 135 & 139 \\
		
		mine     & 70 & 983161 & 429 & 506 \\
		linclust & 70 & 971547 & 585 & 706 \\
		cd-hit   & 70 & 976699 & 560 & 759 \\
		
		mine     & 50 & 592585 & 776 & 1206 \\
		linclust & 50 & 664691 & 835 & 1450 \\
		cd-hit   & 50 & 471363 & 1889 & 4207 \\
		
		\bottomrule
	\end{tabular}
	\label{table:pfam}
\end{table}

Third, we assessed the sensitivity and specificity of our sequence clustering algorithm using manually curated data.
We downloaded the seed A dataset from Pfam version 31.0.
We ran each clustering algorithm on this dataset.
A corrupted cluster contains at least two sequences that belong to two different Pfam families.
A corrupted cluster member belongs to a Pfam family that the representative of this cluster does not belong to.
A more sensitive clustering algorithm produces fewer clusters.
A more specific clustering algorithm produces fewer corrupted clusters and fewer corrupted cluster members.
\Cref{table:pfam} shows that our algorithm usualy produces slightly more clusters.
However, \cref{table:pfam} also shows that our algorithm always produces much fewer corrupted clusters and much fewer corrupted cluster members.
Therefore, our algorithm overall performs the best. 

\section{Conclusion}

Clustering of protein sequences is a fundamental problem in Biology.
We developed a new clustering algorithm that is in general more sensitive, more specific, and faster than known published clustering algorithms.
We observed that cluster topology produced by greedy-incremental update suffers from local optimum.
Therefore, our algorithm delays the assignment of a sequence to an existing cluster and uses greedy set cover to perform such assignment.
We observed that there are too many short words in a protein sequence.
Therefore, our algorithm uses min hashes instead of short words.
We observed that sequence identity is not sufficiently correlated with biological simmilarity and that alignment is time-consuming to compute.
Therefore, our algorithm uses edit-similarity instead of sequence identity.

In the future, we will apply the techniques used in our clustering algorithm to other problems. For example, we may apply our techniques to metagenomic classification, chimera detection, detection of conserved protein domains, etc.
Moreover, our clustering algorithm will generate smaller but more representative non-redundant biological database. Such database will power up FusionCloud\textsuperscript{TM}, a web portal that detects pathogens in NGS data.

%\bibliographystyle{plainnat}
\bibliographystyle{unsrtnat}
\bibliography{clust}

\iffalse

\subsection{Reduction of greediness in greedy incremental update}

Greedy incremental update may not be optimal. 
For example, suppose we would like to cluster the following sequences at 65\% sequence identity:
ABXXEFGHIJ, 
ABXXEFXXI, and
BCDEFXXIJ.
In this case, 65\% sequence identity corresponds to 6 inclusive matches, or equivalently, exclusive edit distance of 4.
Then, greedy incremental update would pick ABXXEFGHIJ as the centroid of the first cluster, 
assign ABXXEFXXI to the first cluster because ABXXEFXXI is 3 edit distance away from ABXXEFGHIJ, 
and pick BCDEFXXIJ as the centroid of the second cluster because BCDEFXXIJ is 4 edit distance away from ABXXEFGHIJ.
However, if ABXXEFXXI is picked as the centroid of the first cluster, then both ABXXEFGHIJ and BCDEFXXIJ would be assigned to the first cluster. 

Instead of performing clustering while iterating through all sequences, we can perform clustering after computing the pairwise sequence identity of all sequences. 
In this case, sequence clustering is formulated as the dominating set problem, which is a special type of the set-cover problem. 
In this dominating set problem, an edge from a first vertex to a second vertex means that the first corresponding biological sequence can represent the second corresponding biological sequence. 

However, we observed that, for biological databases such as uniprot, the number of edges is orders of magnitude more numerous than the number of vertices. Therefore, exhaustive generation of all edges requires substantial computational resources.
At the same time, such biological databases induce graphs characterized by rare cliques of large sizes, presumably because some biomolecules are over-represented due to their biological importance and/or abundance.
Therefore, if an unvisited sequence is already represented by many other visited sequences that approximately form a clique, then this unvisited sequence is unlikely to form a new cluster that can contain members outside of this clique. 
Therefore, in this case, we do not determine the sequences that this new sequence can represent, and therefore do not generate any edge starting from the vertex corresponding to this new sequence. 
Therefore, the resulting graph is incomplete but does not substantially affect the optimality of the resulting dominating set problem.

Then, we the greedy set-cover algorithm to solve the dominating set problem on the incomplete graph.
In addition of producing a solution that consists of a set of sequences, 
our greedy set-cover algorithm makes sure that each sequence is only represented by the best representative sequence.
For example, if sequence A can be represented by either representative sequences B or C but A is more similar to C,
then A will be clustered with C.  
Our greedy set-cover algorithm uses linear memory and runtime and is highly optimized for memory usage.

%\cite{steinegger2017linclust} used greedy set cover

\subsection{Throw-away of abundant and uninformative long words}

Some biological sequences contain uninformative region.
For example, a peptide sequence may consist of conserved regions and hypervariable regions.
The higher the sequence identity threshold is, the less informative the conserved region is.
Therefore, two sufficiently dissimilar sequences can still share the same long word in the uninformative region.
If we use a naive long-word filter, then we will initiate a computationally more expensive comparison between these two sequences that share at least one uninformative long word.
An uninformative long word slows down the clustering process only if many sequences share this long word.
Therefore, we rank all long words by percentile in increasing order of abundance.
For each long word that is longer than expected, we used hashed signatures, which are similar to short words in terms of function but are much less computationally intensive to work with, to estimate the sequence identity between some random pairs of sequences sharing this long word.
If the frequency that the estimated sequence identity meets the user-defined threshold is below a certain threshold,
then we throw-away the long word.
A throw-away long word does not initiate further computationally more expensive comparison between two sequences that share this long word.
Therefore, computation time can be saved by removing uninformative long words without much sacrifice in sensitivity.
To reduce memory usage, we use the hash values of long words instead of the long words themselves, which is similar to the technique used in \cite{steinegger2017linclust}.

\subsection{Reduction of short words into hashed signature}

A typical protein sequence consists of about 400 amino acids.
Therefore, two protein sequences typically have two sets of 400 short words each.
However, if we uniformly, randomly, and independently (URI) subsample a small number of short words in each set of short words, then the subsampled short words can still work reasonably well. 
Nonetheless, we still need to maximize the collision rate between two sets of URI subsampled short words.
We used a technique similar to minhash to achieve such URI subsampling while maximizing such collision rate.
In brief, each short word is hashed into a 16-bit unsigned integer.
The 31 smallest hash values form the signature of the sequence.
When we need to compare two sequences, we first compare their signatures.
If their signatures do not share a certain number of hash values in common, then we stop any further comparison between the two sequences. 
Otherwise, we proceed to compare the two sequences using a computationally more expensive method.
Instead of comparing 400 short words, we only have to compare 31 hash values.

A typical nucleotide sequences is usually three times as long as a typical protein sequence.
Therefore, the reduction of short words into signature is even more effective for nucleotide sequences.

One-to-many query-to-target sequence comparison is needed in sequence clustering. 
Similar to \cite{li2006cd}, we sort, in descending order, the targets according to their number of shared hash values with the query before iterating through the targets. 
Similar to \cite{edgar2010search}, we keep track of the number of failed attempts, or equivalently number of false-positive hits, when iterating through targets.
In addition, we keep track of the number of successful attempts, or equivalently number of true-positive hits, while iterating through targets.
Before iterating through the sorted targets, we initialize the number of remaining attempts to a positive integer.
If an attempt fails, we decrement the number of remaining attempts by one.
If an attempt succeeds, we increment the number of remaining attempts by a positive integer.
If the number of attempts becomes zero, then we stop iterating through the targets, because the not-yet-iterated remaining targets are not likely to be true positive hits.
The idea is that the ratio of success to failure should be above a certain threshold given a Bayesian prior of such ratio.

\subsection{Use of edit similarity instead of sequence identity}

Pairwise sequence identity is defined as the number of identical residues in a pairwise sequence alignment, divided by either the length of the alignment or the length of the shortest sequence. 
Unless explicitly stated otherwise, we assume that the sequence alignment used to generate sequence identity is the optimal alignment in terms of alignment score.

We developed a new measure of similarity between two sequences called edit-similarity.
The edit-similarity between a query and a target is defined as: the length of the target minus the number of edits required such that the target is a substring of the query, divided by the length of the target.
In terms of definition, edit-similarity is almost identical to the similarity in table 1 of \cite{vsovsic2017edlib}, 
except that edit-similarity uses target length as divisor whereas the similarity in \cite{vsovsic2017edlib} uses min(query-length, target-length) as the divisor. 
For example, the edit-similarity between \texttt{ACGGT} and \texttt{ATGG} is (4-1)/4, and the edit-similarity between \texttt{ATGG} and \texttt{ACGGT} is (5-2)/5.
The query is said to cover the target if the edit-similarity between the query and the target is higher than a predefined threshold.

Edit-distance requires much less computational time than pairwise alignment with substitution matrix, gap opening penalty, and gap extension penalty \cite{vsovsic2017edlib}. 
At first glance, it seems that we would lose some information by not computing pairwise alignment. 
However, it turns out that edit-similarity is biologically more relevant than sequence identity.
In the next two paragraphs, we will heuristically explain why edit-similarity is biologically more relevant.
In \ref{fig:specificity}, we will show that edit-similarity is more correlated with protein structural similarity than sequence identity.

Let \(s_1\) and \(s_2\) be two sequences such that \(s_1\) is longer than \(s_2\).
Let \(I(s_1, s_2)\) be the sequence identity between \(s_1\) and \(s_2\).
Let \(E(s_1, s_2)\) be the edit-similarity between \(s_1\) and \(s_2\).
If \(I(s_1, s_2) < E(s_1, s_2)\), then the alignment used to generate \(I(s_1, s_2)\) has fewer matches of identical residues, but more alignment score, than the alignment used to generate \(E(s_1, s_2)\).
Therefore, the alignment used to generate \(I(s_1, s_2)\) must have in general more conserved amino-acid substitutions than the alignment used to generate \(E(s_1, s_2)\) in order to produce higher alignment score with less sequence identity.
However, the more conserved amino-acid substitutions from \(I(s_1, s_2)\) imply that \(I(s_1, s_2)\) probably underestimates the true biological similarity between \(s_1\) and \(s_2\) anyway, because more conserved amino-acid substitutions have bigger impact on protein structures and functions.
Therefore, \(E(s_1, s_2)\) measures better the true biological similarity between \(s_1\) and \(s_2\) than \(I(s_1, s_2)\) even though the alignment used to compute \(I(s_1, s_2)\) can provide a white-box explanation for the relationship between \(s_1\) and \(s_2\).
For example, suppose \(s_1 = \texttt{AIAISSRRSSWWW}\) and \(s_2 = \texttt{AIAIWWW}\), 
and suppose we use blosum62 matrix for computing \(I(s_1, s_2)\).
In blosum62, the match reward for \texttt{W} is 11, and the match reward for both \texttt{A} and \texttt{I} is 4.
Therefore, \(I(s_1, s_2) = 4/7\) because the           chunk \texttt{AIAI} is shared between \(s_1\) and \(s_2\).
but \(E(s_1, s_2) = 3/7\) because the conserved chunk \texttt{WWW}  is shared between \(s_1\) and \(s_2\).
However, since \texttt{W} is so conserved, \(3/7\) is an underestimates of the extend of biological relationship between \(s_1\) and \(s_2\).
Therefore, \(4/7\) is closer to such extend of biological relationship.

Edit similarity is supposed to be uncorrelated with conservation of amino-acid residues, but sequence identity can be negatively correlated with conservation of amino-acid residues.
In addition, edit similarity considers deletion of \(s_1\) in \(s_2\), whereas sequence identity ignores deletion of \(s_1\) in \(s_2\).
For example, the edit similarity between \texttt{AAACGGG} and \texttt{AAAGGG} is (6-1)/6, but the corresponding sequence identity is 1. Therefore, edit similarity is supposed to be more informative than sequence identity if part of the longer sequence is deleted in the shorter sequence.

\fi

\end{document}
